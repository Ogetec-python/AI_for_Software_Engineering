{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f84dfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PREDICTIVE ANALYTICS FOR RESOURCE ALLOCATION\n",
      "Using ML to predict issue priority levels\n",
      "======================================================================\n",
      "\n",
      "[STEP 1] Loading Dataset...\n",
      "Dataset Shape: (569, 30)\n",
      "Number of Features: 30\n",
      "Number of Samples: 569\n",
      "\n",
      "Priority Distribution:\n",
      "High      212\n",
      "Low       119\n",
      "Medium    238\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[STEP 2] Data Preprocessing...\n",
      "Missing values: 0\n",
      "\n",
      "Feature Statistics:\n",
      "       mean radius  mean texture  mean perimeter    mean area  mean smoothness\n",
      "count   569.000000    569.000000      569.000000   569.000000       569.000000\n",
      "mean     14.127292     19.289649       91.969033   654.889104         0.096360\n",
      "std       3.524049      4.301036       24.298981   351.914129         0.014064\n",
      "min       6.981000      9.710000       43.790000   143.500000         0.052630\n",
      "25%      11.700000     16.170000       75.170000   420.300000         0.086370\n",
      "50%      13.370000     18.840000       86.240000   551.100000         0.095870\n",
      "75%      15.780000     21.800000      104.100000   782.700000         0.105300\n",
      "max      28.110000     39.280000      188.500000  2501.000000         0.163400\n",
      "\n",
      "Training set size: 455\n",
      "Testing set size: 114\n",
      "✓ Features scaled using StandardScaler\n",
      "\n",
      "[STEP 3] Training Random Forest Model...\n",
      "✓ Model trained successfully\n",
      "\n",
      "[STEP 4] Model Evaluation...\n",
      "\n",
      "======================================================================\n",
      "PERFORMANCE METRICS\n",
      "======================================================================\n",
      "\n",
      "Training Set:\n",
      "  Accuracy:  0.9648 (96.48%)\n",
      "  F1-Score:  0.9644\n",
      "\n",
      "Testing Set:\n",
      "  Accuracy:  0.7544 (75.44%)\n",
      "  F1-Score:  0.6977\n",
      "\n",
      "======================================================================\n",
      "CLASSIFICATION REPORT (Test Set)\n",
      "======================================================================\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  High Priority       0.91      0.93      0.92        42\n",
      "Medium Priority       0.67      0.94      0.78        48\n",
      "   Low Priority       0.50      0.08      0.14        24\n",
      "\n",
      "       accuracy                           0.75       114\n",
      "      macro avg       0.69      0.65      0.61       114\n",
      "   weighted avg       0.72      0.75      0.70       114\n",
      "\n",
      "\n",
      "======================================================================\n",
      "CONFUSION MATRIX\n",
      "======================================================================\n",
      "[[39  2  1]\n",
      " [ 2 45  1]\n",
      " [ 2 20  2]]\n",
      "\n",
      "Rows: Actual Priority | Columns: Predicted Priority\n",
      "Order: High (0), Medium (1), Low (2)\n",
      "\n",
      "[STEP 5] Feature Importance Analysis...\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "             feature  importance\n",
      "          worst area    0.120708\n",
      "worst concave points    0.091094\n",
      "        worst radius    0.074878\n",
      "     worst perimeter    0.064541\n",
      " mean concave points    0.061534\n",
      "      mean perimeter    0.054014\n",
      "      mean concavity    0.047473\n",
      "         mean radius    0.045889\n",
      "           mean area    0.045434\n",
      "     worst concavity    0.035446\n",
      "\n",
      "======================================================================\n",
      "MODEL INSIGHTS & RECOMMENDATIONS\n",
      "======================================================================\n",
      "\n",
      "1. PERFORMANCE ANALYSIS:\n",
      "   - High accuracy indicates the model can reliably predict issue priorities\n",
      "   - F1-score measures balance between precision and recall\n",
      "   - Good generalization if test metrics are close to training metrics\n",
      "\n",
      "2. RESOURCE ALLOCATION IMPLICATIONS:\n",
      "   - High Priority issues: Allocate senior developers immediately\n",
      "   - Medium Priority: Schedule within current sprint\n",
      "   - Low Priority: Add to backlog for future sprints\n",
      "\n",
      "3. FEATURE IMPORTANCE:\n",
      "   - Top features reveal key indicators of issue severity\n",
      "   - Focus on these metrics during issue triage\n",
      "   - Can be used for automated routing\n",
      "\n",
      "4. CONTINUOUS IMPROVEMENT:\n",
      "   - Retrain model monthly with new labeled data\n",
      "   - Monitor for concept drift (changing patterns)\n",
      "   - Collect feedback on prediction accuracy\n",
      "\n",
      "\n",
      "[STEP 7] Sample Predictions...\n",
      "\n",
      "Sample Issue Predictions:\n",
      "----------------------------------------------------------------------\n",
      "✗ Issue #23\n",
      "  Actual: Low | Predicted: High | Confidence: 39.6%\n",
      "✓ Issue #55\n",
      "  Actual: Medium | Predicted: Medium | Confidence: 56.8%\n",
      "✓ Issue #17\n",
      "  Actual: Medium | Predicted: Medium | Confidence: 69.5%\n",
      "✓ Issue #84\n",
      "  Actual: High | Predicted: High | Confidence: 63.3%\n",
      "✓ Issue #37\n",
      "  Actual: Medium | Predicted: Medium | Confidence: 59.0%\n",
      "\n",
      "======================================================================\n",
      "ANALYSIS COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Performance Summary:\n",
      "  Model: Random Forest Classifier\n",
      "  Training Accuracy: 0.9648\n",
      "  Testing Accuracy: 0.7544\n",
      "  Training F1-Score: 0.9644\n",
      "  Testing F1-Score: 0.6977\n",
      "  Dataset Size: 569\n",
      "  Number of Features: 30\n",
      "  Classes: 3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Predictive Analytics for Resource Allocation\n",
    "Using Breast Cancer Dataset as proxy for issue classification\n",
    "Task: Predict issue priority (high/medium/low) based on features\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PREDICTIVE ANALYTICS FOR RESOURCE ALLOCATION\")\n",
    "print(\"Using ML to predict issue priority levels\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD AND PREPARE DATA\n",
    "# ============================================================================\n",
    "print(\"\\n[STEP 1] Loading Dataset...\")\n",
    "\n",
    "# Load breast cancer dataset (proxy for software issues)\n",
    "# Features represent issue characteristics (complexity metrics, dependencies, etc.)\n",
    "# Target represents priority levels\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "# Convert binary classification to multi-class (simulating priority levels)\n",
    "# Original: 0=malignant, 1=benign\n",
    "# New: 0=high priority, 1=medium priority, 2=low priority\n",
    "# We'll create a synthetic third class for demonstration\n",
    "np.random.seed(42)\n",
    "y_multiclass = y.copy()\n",
    "\n",
    "# Convert some medium priority (1) to low priority (2)\n",
    "medium_indices = np.where(y_multiclass == 1)[0]\n",
    "low_priority_indices = np.random.choice(medium_indices, size=len(medium_indices)//3, replace=False)\n",
    "y_multiclass[low_priority_indices] = 2\n",
    "\n",
    "# Rename for clarity\n",
    "priority_mapping = {0: 'High', 1: 'Medium', 2: 'Low'}\n",
    "priority_labels = [priority_mapping[i] for i in y_multiclass]\n",
    "\n",
    "print(f\"Dataset Shape: {X.shape}\")\n",
    "print(f\"Number of Features: {X.shape[1]}\")\n",
    "print(f\"Number of Samples: {X.shape[0]}\")\n",
    "print(f\"\\nPriority Distribution:\")\n",
    "print(pd.Series(priority_labels).value_counts().sort_index())\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: DATA PREPROCESSING\n",
    "# ============================================================================\n",
    "print(\"\\n[STEP 2] Data Preprocessing...\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"Missing values: {X.isnull().sum().sum()}\")\n",
    "\n",
    "# Feature statistics\n",
    "print(\"\\nFeature Statistics:\")\n",
    "print(X.describe().iloc[:, :5])  # Show first 5 features\n",
    "\n",
    "# Split data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_multiclass, test_size=0.2, random_state=42, stratify=y_multiclass\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Feature scaling (standardization)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"✓ Features scaled using StandardScaler\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: MODEL TRAINING\n",
    "# ============================================================================\n",
    "print(\"\\n[STEP 3] Training Random Forest Model...\")\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,      # Number of trees\n",
    "    max_depth=10,          # Maximum depth of trees\n",
    "    min_samples_split=5,   # Minimum samples to split a node\n",
    "    min_samples_leaf=2,    # Minimum samples in leaf node\n",
    "    random_state=42,\n",
    "    n_jobs=-1              # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"✓ Model trained successfully\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: MODEL EVALUATION\n",
    "# ============================================================================\n",
    "print(\"\\n[STEP 4] Model Evaluation...\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train_scaled)\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Calculate F1-score (weighted average for multi-class)\n",
    "train_f1 = f1_score(y_train, y_pred_train, average='weighted')\n",
    "test_f1 = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PERFORMANCE METRICS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  Accuracy:  {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "print(f\"  F1-Score:  {train_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nTesting Set:\")\n",
    "print(f\"  Accuracy:  {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"  F1-Score:  {test_f1:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CLASSIFICATION REPORT (Test Set)\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred_test,\n",
    "    target_names=['High Priority', 'Medium Priority', 'Low Priority']\n",
    "))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\" * 70)\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "print(cm)\n",
    "print(\"\\nRows: Actual Priority | Columns: Predicted Priority\")\n",
    "print(\"Order: High (0), Medium (1), Low (2)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: FEATURE IMPORTANCE ANALYSIS\n",
    "# ============================================================================\n",
    "print(\"\\n[STEP 5] Feature Importance Analysis...\")\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10).to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: MODEL INSIGHTS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL INSIGHTS & RECOMMENDATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "1. PERFORMANCE ANALYSIS:\n",
    "   - High accuracy indicates the model can reliably predict issue priorities\n",
    "   - F1-score measures balance between precision and recall\n",
    "   - Good generalization if test metrics are close to training metrics\n",
    "\n",
    "2. RESOURCE ALLOCATION IMPLICATIONS:\n",
    "   - High Priority issues: Allocate senior developers immediately\n",
    "   - Medium Priority: Schedule within current sprint\n",
    "   - Low Priority: Add to backlog for future sprints\n",
    "\n",
    "3. FEATURE IMPORTANCE:\n",
    "   - Top features reveal key indicators of issue severity\n",
    "   - Focus on these metrics during issue triage\n",
    "   - Can be used for automated routing\n",
    "\n",
    "4. CONTINUOUS IMPROVEMENT:\n",
    "   - Retrain model monthly with new labeled data\n",
    "   - Monitor for concept drift (changing patterns)\n",
    "   - Collect feedback on prediction accuracy\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: SAMPLE PREDICTIONS\n",
    "# ============================================================================\n",
    "print(\"\\n[STEP 7] Sample Predictions...\")\n",
    "\n",
    "# Show some example predictions\n",
    "sample_size = 5\n",
    "sample_indices = np.random.choice(len(X_test), sample_size, replace=False)\n",
    "\n",
    "print(\"\\nSample Issue Predictions:\")\n",
    "print(\"-\" * 70)\n",
    "for idx in sample_indices:\n",
    "    actual = priority_mapping[y_test.iloc[idx]]\n",
    "    predicted = priority_mapping[y_pred_test[idx]]\n",
    "    confidence = model.predict_proba(X_test_scaled[idx].reshape(1, -1))[0]\n",
    "    max_confidence = confidence.max() * 100\n",
    "\n",
    "    match_symbol = \"✓\" if actual == predicted else \"✗\"\n",
    "    print(f\"{match_symbol} Issue #{idx}\")\n",
    "    print(f\"  Actual: {actual} | Predicted: {predicted} | Confidence: {max_confidence:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save performance summary\n",
    "performance_summary = {\n",
    "    'Model': 'Random Forest Classifier',\n",
    "    'Training Accuracy': f\"{train_accuracy:.4f}\",\n",
    "    'Testing Accuracy': f\"{test_accuracy:.4f}\",\n",
    "    'Training F1-Score': f\"{train_f1:.4f}\",\n",
    "    'Testing F1-Score': f\"{test_f1:.4f}\",\n",
    "    'Dataset Size': X.shape[0],\n",
    "    'Number of Features': X.shape[1],\n",
    "    'Classes': 3\n",
    "}\n",
    "\n",
    "print(\"\\nPerformance Summary:\")\n",
    "for key, value in performance_summary.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Onyii",
   "language": "python",
   "name": "onyii"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
